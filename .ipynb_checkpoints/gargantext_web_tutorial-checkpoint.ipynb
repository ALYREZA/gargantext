{
 "metadata": {
  "name": "",
  "signature": "sha256:a8678c86f8d94c1ba55469d0e0a796c7d25df5de29707f5114b4cb74858855a8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd .."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/alexandre/projets/gargantext.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gargantext_core as gargantext"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd gargantext_web/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/alexandre/projets/gargantext.py/gargantext_web\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import documents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Imporation\n",
      "## Europresse"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = gargantext.bdd.Europresse()\n",
      "c.add(\"/home/alexandre/projets/abeilles/documents/Europresse/html/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in c:\n",
      "    d = documents.models.Document()\n",
      "    d.project_id = \"1\"\n",
      "    d.corpus_id = \"1\"\n",
      "    d.analyst_id = \"1\"\n",
      "    try:\n",
      "        d.uniqu_id = doc[\"object_id\"]\n",
      "        d.date = doc[\"date\"]\n",
      "        d.title = doc[\"title\"]\n",
      "        d.authors = doc[\"authors\"]\n",
      "        d.text = doc[\"text\"]\n",
      "        d.source = doc[\"source\"]\n",
      "        d.save()\n",
      "    except:\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## ISI (todo)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "projects = documents.models.Project.objects.all()\n",
      "for p in projects:\n",
      "    corpora = documents.models.Corpus.objects.filter(project_id=p.id)\n",
      "    print(p.id, p.title)\n",
      "    for c in corpora:\n",
      "        print(\"|_\", c.id,\":\", c.title)\n",
      "    print(\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3 Hola Ebola\n",
        "\n",
        "2 Fukushima again\n",
        "|_ 7 : Test\n",
        "\n",
        "4 Thanks anthrax\n",
        "\n",
        "1 Bees swarm\n",
        "|_ 4 : Health academic publications\n",
        "|_ 2 : bees and (pesticides or chemicals or neocotinoids)\n",
        "|_ 1 : Quand les abeilles meurent, les articles sont compt\u00e9s\n",
        "\n",
        "6 CIRDEM\n",
        "|_ 8 : Zotero fichier du 9 sept.\n",
        "\n",
        "7 TEST\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractNgrams(corpus_pk=1):\n",
      "    corpus = documents.models.Corpus.objects.get(pk=1)\n",
      "    data = gargantext.Corpus()\n",
      "    docs = data.query('''select *  from documents_document\n",
      "                        where corpus_id = %d\n",
      "                        limit 90;''' % corpus_pk)\n",
      "    words = gargantext.Ngrams()\n",
      "    words.get(docs, key='text', unique_id=\"unique_id\")\n",
      "    return(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.stem.snowball import EnglishStemmer\n",
      "stemmer = EnglishStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = gargantext.Corpus()\n",
      "docs = data.query('''select *  from documents_document\n",
      "                        where corpus_id = %d\n",
      "                        limit 9;''' % 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ngram(terms):\n",
      "    stems = stemmer.stem(terms)\n",
      "    n = len(stems.split(\" \"))\n",
      "    ngram = documents.models.Ngram.objects.get_or_create(terms = terms,\\\n",
      "                                                 stem = stems,\\\n",
      "                                                 n= n)\n",
      "    return(ngram[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc = documents.models.Document.objects.get(pk = 9103)\n",
      "doc.title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "'France/R\u00e9gent TS: contr\u00f4le judiciaire annul\u00e9 pour BASF, confirm\u00e9 pour Bayer'"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gram = ngram(\"de\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def addNgram2doc(gram, doc):\n",
      "    ngramDoc = documents.models.NgramDocument.objects.get_or_create(terms=gram,\\\n",
      "                                                           document = doc,\\\n",
      "                                                           defaults={'occurrences':0})[0]\n",
      "    ngramDoc.occurrences = F('occurrences') + 1\n",
      "    ngramDoc.save()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Insert ngrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "l = set()\n",
      "d = defaultdict(lambda : defaultdict(lambda: defaultdict(lambda: defaultdict(int))))\n",
      "\n",
      "docs = documents.models.Document.objects.all().filter(project_id=1)[:10] \n",
      "\n",
      "for doc in docs:\n",
      "    sentances = nltk.sent_tokenize(doc.text)\n",
      "    for sentance in sentances:\n",
      "        words = nltk.wordpunct_tokenize(sentance)\n",
      "        #print(len(words))\n",
      "        for word in words:\n",
      "            stems = stemmer.stem(word)\n",
      "            new = (word, stems, len(stems.split(\" \")))\n",
      "            l.add(new)\n",
      "            \n",
      "            d[word][doc.id]['count'] = d[word][doc.id].get('count', 0) + 1\n",
      "            \n",
      "\n",
      "new_grams = [documents.models.Ngram(terms=x[0], stem=x[1], n=x[2]) for x in l]\n",
      "new_gramDoc = [ documents.models.NgramDocumentTemporary(terms=k, document=pk, occurrences=d[k][pk]['count']) \\\n",
      "               for k in d.keys() \\\n",
      "               for pk in d[k].keys()\\\n",
      "               ]\n",
      "\n",
      "documents.models.NgramTemporary.objects.bulk_create(new_grams)\n",
      "documents.models.NgramDocumentTemporary.objects.bulk_create(new_gramDoc)\n",
      "\n",
      "from django.db import connection\n",
      "cursor = connection.cursor()\n",
      "# LOCK TABLE documents_ngramtemporary IN EXCLUSIVE MODE;\n",
      "query_string = \"\"\"\n",
      "                 INSERT INTO documents_ngram \n",
      "                 SELECT * FROM documents_ngramtemporary WHERE NOT EXISTS \n",
      "                 ( SELECT 1 FROM documents_ngram WHERE \n",
      "                 documents_ngram.terms = documents_ngramtemporary.terms);\n",
      "                 \n",
      "                 delete from documents_ngramtemporary;\n",
      "                 \n",
      "                 INSERT INTO documents_ngramdocument\n",
      "                 SELECT * FROM documents_ngramdocumenttemporary WHERE NOT EXISTS \n",
      "                 ( SELECT 1 FROM documents_ngram WHERE \n",
      "                 documents_ngram.terms = documents_ngramtemporary.terms);\n",
      "                 \n",
      "                 delete from documents_ngramtemporary;\n",
      "             \"\"\"\n",
      "cursor.execute(query_string)\n",
      "\n",
      "try:\n",
      "    while True:\n",
      "        row = cursor.fetchone()\n",
      "        if row is None:\n",
      "            break\n",
      "        print(row)\n",
      "except:\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Insert NgramsDoc"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Copy Postgres"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "curs.execute(\"select * from documents_project;\")\n",
      "curs.fetchone()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "(3, datetime.date(2014, 9, 8), 1, 'Hola Ebola', 'Dance with the risks', {})"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# anything can be used as a file if it has .read() and .readline() methods\n",
      "import io\n",
      "data = io.StringIO()\n",
      "data.write('\\n'.join(['Test\\tretest\\t2',\n",
      "                  'Madonna\\tMado\\t45',\n",
      "                  'Federico\\tDi Gregorio\\t3']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "52"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.seek(0)\n",
      "curs.copy_from(data, 'documents_ngramtemporary', columns=('terms', 'stem', 'n'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "InternalError",
       "evalue": "ERREUR:  la transaction est annul\u00e9e, les commandes sont ignor\u00e9es jusqu'\u00e0 la fin du bloc\nde la transaction\n",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-82-a9cf2ba7718f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcurs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'documents_ngramtemporary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'terms'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stem'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mInternalError\u001b[0m: ERREUR:  la transaction est annul\u00e9e, les commandes sont ignor\u00e9es jusqu'\u00e0 la fin du bloc\nde la transaction\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = extractNgrams()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "local variable 'x' referenced before assignment\n",
        "local variable 'x' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local variable 'x' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local variable 'x' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local variable 'x' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local variable 'x' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local variable 'x' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "local variable 'x' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-9-d62560425026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractNgrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-8-520b3bdbed28>\u001b[0m in \u001b[0;36mextractNgrams\u001b[1;34m(corpus_pk)\u001b[0m\n\u001b[0;32m      6\u001b[0m                         limit 90;''' % corpus_pk)\n\u001b[0;32m      7\u001b[0m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgargantext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNgrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unique_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/alexandre/projets/gargantext.py/gargantext_core/analysis/ngrams.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, corpus, lang, key, unique_id)\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'XX'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[0mngrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfouille\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/alexandre/projets/gargantext.py/gargantext_core/analysis/ngrams.py\u001b[0m in \u001b[0;36mfouille\u001b[1;34m(text, grammar_rule)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msentance\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentances\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtrees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/alexandre/projets/gargantext.py/gargantext_core/analysis/languages.py\u001b[0m in \u001b[0;36mfrench_pos_tag\u001b[1;34m(sentance)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mTAGINENC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         TAGOUTENC='utf-8')\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTagText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/alexandre/projets/gargantext.py/env/lib/python3.4/site-packages/treetaggerwrapper.py\u001b[0m in \u001b[0;36mTagText\u001b[1;34m(self, text, numlines, tagonly, prepronly, tagblanks, notagurl, notagemail, notagip, notagdns, encoding, errors)\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[0mintext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagoutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read from TreeTagger: %r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = documents.models.Document()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in x.stems.keys():\n",
      "    print(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('m\u00e9decin', 'classiqu')\n",
        "('canc',)\n",
        "('sourc', 'proch')\n",
        "('carriol', '\u00e0', 'bagard')\n",
        "('plant', 'cultiv')\n",
        "('apr\u00e8s-mid', 'r\u00e9cr\u00e9at')\n",
        "('ouest-fr', 'sarth', 'sud')\n",
        "('jeun', '\u00e9lev')\n",
        "('naus',)\n",
        "('adult',)\n",
        "('apres',)\n",
        "('maison',)\n",
        "('l',)\n",
        "('jeud', 'soir')\n",
        "('unaf',)\n",
        "('don',)\n",
        "('assurance-malad',)\n",
        "('sol',)\n",
        "('film', 'nos', 'enfant')\n",
        "('concurrent', 'bai', 'cropscienc', 'franc')\n",
        "('annul', 'd\u00e9pos')\n",
        "('tel',)\n",
        "('afriqu',)\n",
        "('\u00eatre', '\u00e0', 'pied')\n",
        "('group', 'lyon')\n",
        "('quincy',)\n",
        "('frelon', 'europ\u00e9en')\n",
        "('mati', 'premi')\n",
        "('d\u00e9sign', 'coupabl')\n",
        "('\u00e9poqu',)\n",
        "('affair',)\n",
        "('bardeau',)\n",
        "('jean-luc', 'souli')\n",
        "('contr\u00f4l', 'judiciair')\n",
        "('commercialis',)\n",
        "('lieu',)\n",
        "('semenc', 'trait')\n",
        "('pr\u00e9par',)\n",
        "('bai',)\n",
        "('autr', 'problem')\n",
        "('allerg',)\n",
        "('suspens',)\n",
        "('a-t-il', 'ajout')\n",
        "('cadr',)\n",
        "('absenc',)\n",
        "('unit', 'finist\u00e9rien')\n",
        "('infos', 'econom', 'r\u00e9gent', 't')\n",
        "('commun',)\n",
        "('semenc',)\n",
        "('march', 'mondial')\n",
        "('ventr',)\n",
        "('not',)\n",
        "('jean-mar',)\n",
        "('jeud',)\n",
        "('pet', 'boul')\n",
        "('arbre',)\n",
        "('examen',)\n",
        "('asi',)\n",
        "('jour',)\n",
        "('agricultur', 'biolog')\n",
        "('soir',)\n",
        "('m\u00e9decin', 'hom\u00e9opath')\n",
        "('client',)\n",
        "('meus', 'vi', 'quotidien')\n",
        "('croissanc',)\n",
        "('toit',)\n",
        "('mal-\u00eatr', 'g\u00e9n\u00e9ral')\n",
        "('excellent', 'miel')\n",
        "('\u00e9tudi', 'domicili')\n",
        "('nouveaut',)\n",
        "('chiffr',)\n",
        "('d\u00e9monstr',)\n",
        "('sit', 'brestois')\n",
        "('bas',)\n",
        "('volet',)\n",
        "('v\u00e9g\u00e9tal',)\n",
        "('histoir',)\n",
        "('haute-garon',)\n",
        "('jug', 'rama\u00ebl')\n",
        "('mariag',)\n",
        "('pr\u00e9dateur',)\n",
        "('homm',)\n",
        "('rachat',)\n",
        "('id\u00e9',)\n",
        "('\u00e9vident',)\n",
        "('produit',)\n",
        "('infarctus',)\n",
        "('sid',)\n",
        "('fruit',)\n",
        "('deuxiem',)\n",
        "('dgal', 'paris')\n",
        "('r\u00e9sum',)\n",
        "('visiteur',)\n",
        "('public', 'passion')\n",
        "('vend\u00f4mois',)\n",
        "('\u00e9l\u00e9ment', 'naturel')\n",
        "('surmortal',)\n",
        "('appris', 'aupres')\n",
        "('dat',)\n",
        "('r\u00e9guli',)\n",
        "('nid',)\n",
        "('venin',)\n",
        "('recel',)\n",
        "('but',)\n",
        "('recherch', 'perp\u00e9tuel')\n",
        "('chauffag',)\n",
        "('vi',)\n",
        "('environ',)\n",
        "('f\u00e9mur',)\n",
        "('long',)\n",
        "('f\u00e9vri',)\n",
        "('cons\u00e9quent', 'p\u00e9nal')\n",
        "('infos', 'econom', 'franc')\n",
        "('hygien', 'tres', 'draconien')\n",
        "('nichoir', 'r\u00e9alis')\n",
        "('patholog',)\n",
        "('expos',)\n",
        "('\u00e9gal',)\n",
        "('illustr',)\n",
        "('pert',)\n",
        "('magistrat', 'toulousain')\n",
        "('macer',)\n",
        "('ceven',)\n",
        "('rayon',)\n",
        "('proven',)\n",
        "('l\u00e9gum',)\n",
        "('ateli',)\n",
        "('bagard',)\n",
        "('d\u00e9but', 'mar')\n",
        "('group',)\n",
        "('conf\u00e9der', 'paysan')\n",
        "('moment',)\n",
        "('reper',)\n",
        "('surexploit', 'industriel')\n",
        "('m\u00eam',)\n",
        "('plaint',)\n",
        "('utilis', 'massif')\n",
        "('fractur',)\n",
        "('besseg',)\n",
        "('\u00e9quinox',)\n",
        "('h\u00f4tel', '\u00e0', 'insect')\n",
        "('doublon',)\n",
        "('dimanch',)\n",
        "('produit', 'hom\u00e9opath')\n",
        "('\u00e9colog',)\n",
        "('aven',)\n",
        "(\"c\u00f4tes-d'armor\",)\n",
        "('f\u00e9liqu',)\n",
        "('vu', '\u00e9conom')\n",
        "('canton',)\n",
        "('eau',)\n",
        "('paris',)\n",
        "('charg',)\n",
        "('ouest-fr',)\n",
        "('coll\u00e8gu',)\n",
        "('demand',)\n",
        "('anxiet',)\n",
        "('saint-gauden', 'jean', 'guary')\n",
        "('tres', 'satisfais')\n",
        "('imm\u00e9diat',)\n",
        "('condit',)\n",
        "('bouff',)\n",
        "('part', 'civil')\n",
        "('mort',)\n",
        "('bai', 'toulous')\n",
        "('journ', 'port')\n",
        "('magistrat',)\n",
        "('il',)\n",
        "('lydi', 'gravil')\n",
        "('croissanc', 'correct')\n",
        "('bon', 'rep')\n",
        "('comprim',)\n",
        "('beau', 'r\u00e9sultat')\n",
        "('\u00e9pileps',)\n",
        "('part',)\n",
        "('inflig',)\n",
        "('saint-gauden',)\n",
        "('est', 'r\u00e9publicain')\n",
        "('centr',)\n",
        "('march',)\n",
        "('d\u00e9savantag',)\n",
        "('point',)\n",
        "('europ',)\n",
        "('appel',)\n",
        "('d\u00e9bat',)\n",
        "('gerb',)\n",
        "('tub',)\n",
        "('product',)\n",
        "('d\u00e9tracteur',)\n",
        "('ramassag',)\n",
        "('aliment', 'viv')\n",
        "('vendred',)\n",
        "('an',)\n",
        "('local',)\n",
        "('manifest', 'ax\u00e9')\n",
        "('ann\u00e9',)\n",
        "('associ',)\n",
        "('vin',)\n",
        "('r\u00e9colt',)\n",
        "('fan',)\n",
        "('\u00eatre', 'pr\u00e9sent')\n",
        "('union', 'national')\n",
        "('fusion',)\n",
        "('promen',)\n",
        "('tres', 'simpl')\n",
        "('\u00e9co-pieg',)\n",
        "('fabriqu',)\n",
        "('mid', 'libr')\n",
        "('seb',)\n",
        "('\u00a9',)\n",
        "('grand', 'instanc')\n",
        "('femm', 'favor')\n",
        "('destruct',)\n",
        "('particip',)\n",
        "('centr', 'cultur')\n",
        "('\u00e9nerg', 'nucl\u00e9air')\n",
        "('arriv',)\n",
        "('sifflet', 'bref')\n",
        "('indemnis',)\n",
        "('tri',)\n",
        "('minister',)\n",
        "('victim',)\n",
        "('r\u00e9gent',)\n",
        "('\u00e9chos', 'de', 'la', 'cez', 'semain', 'bleu')\n",
        "('lot',)\n",
        "('aub',)\n",
        "('tribunal',)\n",
        "('direct', 'g\u00e9n\u00e9ral')\n",
        "('mck',)\n",
        "('emploi', 'anthonin', 'debran')\n",
        "('jug', 'guary')\n",
        "('saccharos',)\n",
        "('teintur', 'mer')\n",
        "('m\u00e9dic',)\n",
        "('autoris',)\n",
        "('insect', 'diver')\n",
        "('sos', 'abeil')\n",
        "('enqu\u00eat',)\n",
        "('solut', 'fiabl')\n",
        "('indique-t-il',)\n",
        "('amour',)\n",
        "('b\u00e9b\u00eat',)\n",
        "('\ufffduvr',)\n",
        "('mesur',)\n",
        "('robert',)\n",
        "('semain',)\n",
        "('salari',)\n",
        "('aliment',)\n",
        "('objet',)\n",
        "('boiron',)\n",
        "('b\u00eat',)\n",
        "('situat',)\n",
        "('est', 'r\u00e9publicain', 'ver')\n",
        "('sein',)\n",
        "('kergaradec',)\n",
        "('\u00e0', 'savigny-sur-bray')\n",
        "('ex-propri\u00e9tair',)\n",
        "('ph\u00e9nomen', 'nouveau')\n",
        "('confirm',)\n",
        "('reproduct',)\n",
        "('ouest-fr', 'finister')\n",
        "('cha\u00een', 'compl\u00e9mentair')\n",
        "('bernard', 'fau')\n",
        "('\u00e9cosystem',)\n",
        "('sac',)\n",
        "('arr\u00eat',)\n",
        "('oiseau',)\n",
        "('million',)\n",
        "('ajout', 'inconsider')\n",
        "('apiculteur',)\n",
        "('dgal',)\n",
        "('lydi', 'villefeu')\n",
        "('couleur',)\n",
        "('espec', 'animal')\n",
        "('societ', 'basf', 'agro')\n",
        "('titr',)\n",
        "('quart',)\n",
        "('nombreux', 'expliqu')\n",
        "('samed',)\n",
        "('ancien', 'propri\u00e9tair')\n",
        "('organis',)\n",
        "('ale', 'le', '\u00e9chos', 'de', 'la', 'cez', 'semain', 'bleu')\n",
        "('tgi',)\n",
        "('\u00e9tabl',)\n",
        "('supprim',)\n",
        "('condit', 'tres', 'sp\u00e9cif')\n",
        "('honneur',)\n",
        "('semain', 'bleu')\n",
        "('apr\u00e8s-mid',)\n",
        "('principal', 'mission')\n",
        "('milieu', 'naturel')\n",
        "('conseil', 'g\u00e9n\u00e9ral')\n",
        "('human',)\n",
        "('insect',)\n",
        "('\u00e9ventuel', 'nociv')\n",
        "('pain',)\n",
        "('r\u00e9pet',)\n",
        "('octobr',)\n",
        "('g\u00e9n\u00e9ral',)\n",
        "('\u00e9quilibr', 'parf')\n",
        "('lead', 'mondial')\n",
        "('\u00e9coul',)\n",
        "('bien',)\n",
        "('bibliothequ', 'municipal')\n",
        "('m\u00e9dic', 'traditionnel')\n",
        "('stock',)\n",
        "('sourc', 'judiciair')\n",
        "('espec', 'v\u00e9g\u00e9tal')\n",
        "('vapeur',)\n",
        "('contenu',)\n",
        "('pharmacien',)\n",
        "('trac',)\n",
        "('d\u00e9pen',)\n",
        "('affair', 'jurid')\n",
        "('sp\u00e9cial',)\n",
        "('mas', 'serret')\n",
        "('format',)\n",
        "('vol',)\n",
        "('propri\u00e9tair',)\n",
        "('sommeil',)\n",
        "('docu', 'suit')\n",
        "('insecticid', 'r\u00e9gent')\n",
        "('caution',)\n",
        "('contr\u00f4l',)\n",
        "('origin', 'v\u00e9g\u00e9tal')\n",
        "('extinct',)\n",
        "('bai', 'cropscienc', 'franc')\n",
        "('habitud',)\n",
        "('problem', 'environnemental')\n",
        "('mercred',)\n",
        "('machin',)\n",
        "('zon',)\n",
        "('travail',)\n",
        "('f\u00e9vri', 'derni')\n",
        "('agricultur',)\n",
        "('basf', 'agro')\n",
        "('chemin',)\n",
        "('frelon', 'asiat')\n",
        "('mond', 'enti')\n",
        "('vill',)\n",
        "('natur',)\n",
        "('mid', 'libr', 'lozer')\n",
        "('frelon',)\n",
        "('parcour',)\n",
        "('monstr',)\n",
        "('camion', 'frigorif')\n",
        "('\u00e0', 'vend\u00f4m')\n",
        "('chambr',)\n",
        "('cas',)\n",
        "('nouveau', 'sp\u00e9cial')\n",
        "('mair',)\n",
        "('jardin', 'familial')\n",
        "('laboratoir',)\n",
        "('charpenti',)\n",
        "('droit',)\n",
        "('exempl',)\n",
        "('toulous',)\n",
        "('raison',)\n",
        "('gu\u00e9rand',)\n",
        "('basf',)\n",
        "('difficult', '\u00e0')\n",
        "('docu', 'communiqu')\n",
        "('produit', 'chimiqu')\n",
        "('horticulteur',)\n",
        "('degr',)\n",
        "('milit', 'agriculteur')\n",
        "('infirmi',)\n",
        "('bateau',)\n",
        "('project',)\n",
        "('juin',)\n",
        "('centr', 'culturel')\n",
        "('vice-pr\u00e9sident',)\n",
        "('taigni',)\n",
        "('conf\u00e9rent',)\n",
        "('florenc', 'henry')\n",
        "('chenill', 'processionnair')\n",
        "('montm\u00e9dien',)\n",
        "('renseign',)\n",
        "('centre-ouest',)\n",
        "('gu\u00eap',)\n",
        "('sit',)\n",
        "('disparit',)\n",
        "('essaim', 'd')\n",
        "('fipronil',)\n",
        "('exploit',)\n",
        "('chass', 'cafard')\n",
        "('bernard', 'portales')\n",
        "('\u00e9cout',)\n",
        "('ccas',)\n",
        "('rigolad',)\n",
        "('meilleur', 'v\ufffdu')\n",
        "('abeil',)\n",
        "('chimioth\u00e9rap',)\n",
        "('chaleur',)\n",
        "('moyen',)\n",
        "('diff\u00e9rent', 'pharmacien')\n",
        "('journ',)\n",
        "('dout',)\n",
        "('exploit', 'horticol', '\u00e9colog')\n",
        "('air',)\n",
        "('public',)\n",
        "('autr', 'arr\u00eat')\n",
        "('plac',)\n",
        "('siecl',)\n",
        "('fau',)\n",
        "('directeur|directric',)\n",
        "('tres',)\n",
        "('nouveau', 'ordon', 'conform')\n",
        "('diabet',)\n",
        "('jug',)\n",
        "('cloqu',)\n",
        "('cycl',)\n",
        "('euro',)\n",
        "('anim',)\n",
        "('colleret',)\n",
        "('action',)\n",
        "('br\u00fblur', 'local')\n",
        "('porspod',)\n",
        "('produit', 'issu')\n",
        "('pesticid',)\n",
        "('popul', 'd')\n",
        "('imag',)\n",
        "('trentain',)\n",
        "('aux', 'beau')\n",
        "('proc\u00e9dur',)\n",
        "('terr',)\n",
        "('produit', 'diff\u00e9rent')\n",
        "('yves-mar', 'robin')\n",
        "('moulin', 'robert')\n",
        "('instruct',)\n",
        "('alcool',)\n",
        "('alpe',)\n",
        "('dangeros',)\n",
        "('societ',)\n",
        "('porte-parol', 'jos', 'bov')\n",
        "('coll\u00e8gu', 'jean', 'guary')\n",
        "('occup',)\n",
        "('potag',)\n",
        "('ministr',)\n",
        "('ami',)\n",
        "('sant',)\n",
        "('gest', 'simpl')\n",
        "('fond',)\n",
        "('mis',)\n",
        "('insect', 'tres', 'util')\n",
        "('ndy', '\u00a9')\n",
        "('attent', 'port')\n",
        "('avocat',)\n",
        "('forc',)\n",
        "('f\u00eat',)\n",
        "('femm',)\n",
        "('mond',)\n",
        "('them',)\n",
        "('beau', 'affluenc')\n",
        "('lutf', 'kocyig')\n",
        "('insecticid', 'r\u00e9gent', 't')\n",
        "('r\u00e9seau',)\n",
        "('patienc',)\n",
        "('lactos',)\n",
        "('infos', 'fran\u00e7ais', 'r\u00e9gent', 't')\n",
        "('particuli',)\n",
        "('coup',)\n",
        "('florenc',)\n",
        "('extr\u00eam', 'orient')\n",
        "('d\u00e9cis',)\n",
        "('habitat',)\n",
        "('gard',)\n",
        "('algu',)\n",
        "('anciennet', 'derri')\n",
        "('transmiss',)\n",
        "('facil', '\u00e0')\n",
        "('contact',)\n",
        "('chim',)\n",
        "('lead', 'incontest')\n",
        "('princip', 'actif')\n",
        "('hom\u00e9opath',)\n",
        "('grain',)\n",
        "('norm',)\n",
        "('gamm',)\n",
        "('engrais', 'chimiqu')\n",
        "('c\ufffdur',)\n",
        "('chl', '\u00a9')\n",
        "('concurrent', 'direct')\n",
        "('farin',)\n",
        "('mar', '@ord@')\n",
        "('caus',)\n",
        "('nouveau', 'moyen')\n",
        "('publiqu',)\n",
        "('cultur', 'intens')\n",
        "('moulin',)\n",
        "('d\u00e9part',)\n",
        "('cop',)\n",
        "('fleur',)\n",
        "('dolisos',)\n",
        "('c\u00f4t',)\n",
        "('soin',)\n",
        "('servic',)\n",
        "('bois',)\n",
        "('sujet',)\n",
        "('maxim', 'ortin')\n",
        "('cultur', 'biolog')\n",
        "('\u00eatre',)\n",
        "('derni',)\n",
        "('lois',)\n",
        "('orchestr', 'alain', 'mayo')\n",
        "('nich',)\n",
        "('franc',)\n",
        "('bonheur',)\n",
        "('centre-ouest', 'loir', 'et', 'cher', 'vendom', 'et')\n",
        "('humor', 'andy', 'klein')\n",
        "('morbihan',)\n",
        "('jus',)\n",
        "('pa',)\n",
        "('caracter', 'particuli')\n",
        "('sel',)\n",
        "('jeun',)\n",
        "('plui',)\n",
        "('cultur', 'biolog', 'accessibl')\n",
        "('autr', 'ordon')\n",
        "('docu',)\n",
        "('retrait',)\n",
        "('entretien',)\n",
        "('jug', 'patrick', 'rama\u00ebl')\n",
        "('dossi',)\n",
        "('d\u00e9fens',)\n",
        "('cultur',)\n",
        "('rest',)\n",
        "('curieux',)\n",
        "('anthonin',)\n",
        "('terrain',)\n",
        "('nouvel', 'r\u00e9publ')\n",
        "('kutf',)\n",
        "('\u00e0',)\n",
        "('m\u00e9decin',)\n",
        "('fin',)\n",
        "('gill',)\n",
        "('tout', 'gentil')\n",
        "('pollinis',)\n",
        "('vers',)\n",
        "('cour',)\n",
        "('annul',)\n",
        "('bl\u00e9',)\n",
        "('interdict',)\n",
        "('\u00e9gal', 'pr\u00e9dateur')\n",
        "('long', 'travail')\n",
        "('person',)\n",
        "('brest',)\n",
        "('dizain',)\n",
        "('miel',)\n",
        "('enfant',)\n",
        "('animal',)\n",
        "('copeau',)\n",
        "('tiroir',)\n",
        "('r\u00e9gent', 't')\n",
        "('foi|fois',)\n",
        "('organ',)\n",
        "('plant',)\n",
        "('bon', 'temp')\n",
        "('malad',)\n",
        "('vent',)\n",
        "('apicultur', 'fran\u00e7ais')\n",
        "('antonin',)\n",
        "('futur', '\u00e9poux')\n",
        "('insect', 'nuisibl')\n",
        "('d\u00e9p\u00f4t',)\n",
        "('stress',)\n",
        "('fort', 'progress')\n",
        "('madagascar',)\n",
        "('sall',)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus.language.language"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "'French'"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus_dict:\n",
      "    print(doc.get('title', ''))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gram = documents.models.Ngram()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = documents.models.NgramDocument()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jj_nn = r\"\"\"\n",
      "         NP:  \n",
      "                {<JJ.*>*<NN.*|>+<JJ.*>*}\n",
      "        \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grammar = nltk.sent_tokenize(jj_nn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents.models.Document.objects.raw('select count(*),source from documents_document group by source;'):"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "InvalidQuery",
       "evalue": "Raw query must include the primary key",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mInvalidQuery\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-45-5495b08ea061>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'select count(*),source from documents_document group by source;'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/alexandre/projets/gargantext.py/env/lib/python3.4/site-packages/django/db/models/query.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mskip\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskip\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mInvalidQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Raw query must include the primary key'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1416\u001b[0m             \u001b[0mmodel_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeferred_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mInvalidQuery\u001b[0m: Raw query must include the primary key"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'count': 34, 'source': 'Sud Ouest'}\n",
        "{'count': 26, 'source': 'Le Progr\u00e8s - Lyon'}\n",
        "{'count': 9, 'source': 'Le Figaro'}\n",
        "{'count': 9, 'source': 'AFP Infos Fran\u00e7aises'}\n",
        "{'count': 8, 'source': 'Les Echos'}\n",
        "{'count': 8, 'source': 'Le Monde'}\n",
        "{'count': 6, 'source': 'Le Parisien'}\n",
        "{'count': 5, 'source': 'Le T\u00e9l\u00e9gramme (Bretagne)'}\n",
        "{'count': 4, 'source': 'La Presse'}\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = query_to_dicts('''select to_char(date, 'YYYY-MM'), count(*) \n",
      "                        from documents_document\n",
      "                        group by to_char(date, 'YYYY-MM')\n",
      "                        order by 1 DESC;''')\n",
      "for i in result:\n",
      "    print(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'to_char': '2001-12', 'count': 9}\n",
        "{'to_char': '2001-11', 'count': 10}\n",
        "{'to_char': '2001-10', 'count': 2}\n",
        "{'to_char': '2001-09', 'count': 10}\n",
        "{'to_char': '2001-08', 'count': 36}\n",
        "{'to_char': '2001-07', 'count': 15}\n",
        "{'to_char': '2001-06', 'count': 12}\n",
        "{'to_char': '2001-05', 'count': 13}\n",
        "{'to_char': '2001-04', 'count': 13}\n",
        "{'to_char': '2001-03', 'count': 16}\n",
        "{'to_char': '2001-02', 'count': 14}\n",
        "{'to_char': '2001-01', 'count': 4}\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = query_to_dicts('''select to_char(date, 'YYYY'), count(*) \n",
      "                        from documents_document \n",
      "                        group by to_char(date, 'YYYY')\n",
      "                        order by 1 DESC;''')\n",
      "for i in result:\n",
      "    print(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'to_char': '2001', 'count': 154}\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = query_to_dicts('''select to_char(date, 'YYYY-MM'), count(*) \n",
      "                        from documents_document \n",
      "                        group by to_char(date, 'YYYY-MM')\n",
      "                        order by 1 DESC;''')\n",
      "for i in result:\n",
      "    print(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'to_char': '2001-12', 'count': 9}\n",
        "{'to_char': '2001-11', 'count': 10}\n",
        "{'to_char': '2001-10', 'count': 2}\n",
        "{'to_char': '2001-09', 'count': 10}\n",
        "{'to_char': '2001-08', 'count': 36}\n",
        "{'to_char': '2001-07', 'count': 15}\n",
        "{'to_char': '2001-06', 'count': 12}\n",
        "{'to_char': '2001-05', 'count': 13}\n",
        "{'to_char': '2001-04', 'count': 13}\n",
        "{'to_char': '2001-03', 'count': 16}\n",
        "{'to_char': '2001-02', 'count': 14}\n",
        "{'to_char': '2001-01', 'count': 4}\n"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}